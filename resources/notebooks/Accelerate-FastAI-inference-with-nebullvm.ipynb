{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81872ff",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e64a20",
   "metadata": {},
   "source": [
    "This Notebook implements an easy way for speeding up models trained with FastAI without loosing all the cool functionalities given by the FastAI ecosistem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889aaa2",
   "metadata": {},
   "source": [
    "# Fine tune a fastai model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfd6b17",
   "metadata": {},
   "source": [
    "This section is mainly based on the FastAI notebooks for beginners. This notebook scope is not to be a in-depth guide for the fastai libraries, but, indeed, showing how to properly use nebullvm for accelerating FastAI algorithms at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224), num_workers=0)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e964642",
   "metadata": {},
   "source": [
    "The model will simply classify if the picture contains a cat (`True` label) or a dog (`False` label). Since our aim in this notebook is just to show how to speedup the model, we are not really interested in the meaningfulnes or usefulness of the task itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6e600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_loss, error = learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70ed97",
   "metadata": {},
   "source": [
    "Now that we finetuned the model let's compute how much it takes to run a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f5b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed1fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for _ in range(100):\n",
    "    st = time.time()\n",
    "    preds = learn.predict(files[0])\n",
    "    times.append((time.time()-st)*1000)\n",
    "fastai_vanilla_time = sum(times)/len(times)\n",
    "print(f\"Prediction time: {fastai_vanilla_time} ms,\\nPrediction: {preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8812918",
   "metadata": {},
   "source": [
    "# Optimize the model with nebullvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe42819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nebullvm import optimize_torch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c618fcef",
   "metadata": {},
   "source": [
    "Let's start with optimizing the model. Use nebullvm is super easy: you just need to \n",
    "specify the model, the batch size and the input sizes (for each input, excluding the batch size) and a directory\n",
    "where you want to save the optimized model. In the example we choose the same directory where the model is stored.\n",
    "\n",
    "As yuo can see we also added a further parameter `use_torch_api` that simply is a boolean flag for enabling more\n",
    "optimization capabilities of nebullvm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aacd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for i, (x, y) in enumerate(dls.train):\n",
    "    if i >=10:\n",
    "        break\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "xs = torch.cat(xs, dim=0)\n",
    "ys = torch.cat(ys, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_nebullvm = [((x.unsqueeze(dim=0),), y.unsqueeze(0)) for x, y in zip(xs, ys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f692356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc7029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Without quantization\n",
    "# optimized_model = optimize_torch_model(\n",
    "#     model=original_model,\n",
    "#     batch_size=1,\n",
    "#     input_sizes=[(3, 224, 224)],\n",
    "#     save_dir=\".\",\n",
    "#     use_torch_api=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbf726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With quantization and accuracy as performance metric\n",
    "optimized_model = optimize_torch_model(\n",
    "    model=original_model,\n",
    "    batch_size=1,\n",
    "    save_dir=\".\",\n",
    "    dataloader=dl_nebullvm,\n",
    "    use_torch_api=True,\n",
    "    perf_loss_ths=0.001,\n",
    "    perf_metric=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1991b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With quantization and default precision as perf_metric\n",
    "# optimized_model = optimize_torch_model(\n",
    "#     model=original_model,\n",
    "#     batch_size=1,\n",
    "#     save_dir=\".\",\n",
    "#     dataloader=dl_nebullvm,\n",
    "#     use_torch_api=True,\n",
    "#     perf_loss_ths=3,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, core):\n",
    "        super().__init__()\n",
    "        self.core = optimized_model\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        res = self.core(*args, **kwargs)\n",
    "        if isinstance(res, tuple) and len(res) == 1:\n",
    "            res = res[0]\n",
    "        return res\n",
    "    \n",
    "    def parameters(self, *args, **kwargs):\n",
    "        yield torch.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_model = ModelWrapper(optimized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model = core_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.valid.bs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f05743",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_valid_loss, quant_error = learn.validate(dl=learn.dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fde6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for _ in range(100):\n",
    "    st = time.time()\n",
    "    preds = learn.predict(files[0])\n",
    "    times.append((time.time()-st)*1000)\n",
    "optimized_time = sum(times) / len(times)\n",
    "print(f\"Prediction time: {optimized_time} ms,\\nPrediction: {preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e412875",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Full precision error: {error}\\nQuantization error: {quant_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abbc14",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_username = \"Put here your username\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomment the following line for installing gputil (if you are running on an NVIDIA GPU)\n",
    "#!pip install gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpuinfo\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cpu_info = cpuinfo.get_cpu_info()['brand_raw']\n",
    "gpu_info = \"no\"\n",
    "if torch.cuda.is_available():\n",
    "    import GPUtil\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    gpu_info = list(gpus)[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = f\"\"\"\n",
    "Hello, I'm {your_username}!\n",
    "I've tested nebullvm on the following setup:\n",
    "Hardware: {cpu_info} CPU and {gpu_info} GPU.\n",
    "Model: {learn.arch.__name__} - FastAI for image classification\n",
    "Vanilla performance: {round(fastai_vanilla_time, 2)}ms\n",
    "Optimized performance: {round(optimized_time, 2)}ms\n",
    "Acceleration: {round(fastai_vanilla_time/optimized_time, 1)}x\n",
    "With error increase of {round((quant_error-error)/error*100, 1)}%\n",
    "\"\"\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd40028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
