{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c977e4a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfcd562",
   "metadata": {},
   "source": [
    "Welcome to the guide for speeding up your YOLO model on your specific hardware. \n",
    "\n",
    "The aim of this guide is to show how the nebullvm library can be succesfully used for speeding up your Yolo model\n",
    "on whatever hardware you own (No need of Nvidia GPUs!).\n",
    "\n",
    "The notebook has been created by the team at Nebuly and for any question about it please contact the info service at info@nebuly.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43870917",
   "metadata": {},
   "source": [
    "The Notebook has been tested with pytorch 1.11. It may not work with previous versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f5afa",
   "metadata": {},
   "source": [
    "# Standard YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d727d",
   "metadata": {},
   "source": [
    "Install YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f6a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f49833",
   "metadata": {},
   "source": [
    "Let's start with downloading the model from the torch hub and running a first inference on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc46f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import types\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
    "\n",
    "# Images\n",
    "imgs = ['https://ultralytics.com/images/zidane.jpg']  # batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for _ in range(100):\n",
    "    starting_time = time.time()\n",
    "    # Inference\n",
    "    results = model(imgs)\n",
    "    times.append((time.time()-starting_time)*1000)\n",
    "yolo_vanilla_time = sum(times) / len(times)\n",
    "print(f\"{yolo_vanilla_time} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea18697",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.print()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf19ef7e",
   "metadata": {},
   "source": [
    "Here we are! We got a good prediction, but it took a while :) Let's see if we are able to speed up the model a little bit without losing in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d07ab0",
   "metadata": {},
   "source": [
    "## Optimization with nebullvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nebullvm import optimize_torch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a42b9",
   "metadata": {},
   "source": [
    "First thing, we need to slightly modify the forward method of YOLO since the last layer of the YOLOv5 implementation creates some troubles to some of the DL compilers running on the core of nebullvm. Note that on some types of hardware the nebullvm can optimize the whole net without any problem. However, since we are aiming to be hardware agnostinc in this Notebook, we will split the body of the newtork from its head (the last layer) and optimize just the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_model = copy.deepcopy(model.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _forward_once(self, x, profile=False, visualize=False):\n",
    "    y, dt = [], []  # outputs\n",
    "    for m in self.model:\n",
    "        if m.f != -1:  # if not from previous layer\n",
    "            x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers\n",
    "        if profile:\n",
    "            self._profile_one_layer(m, x, dt)\n",
    "        x = m(x)  # run\n",
    "        y.append(x if m.i in self.save else None)  # save output\n",
    "        if visualize:\n",
    "            feature_visualization(x, m.type, m.i, save_dir=visualize)\n",
    "    self.last_y = y\n",
    "    return x\n",
    "core_model._forward_once = types.MethodType(_forward_once, core_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197ca91",
   "metadata": {},
   "source": [
    "The reimplementation of the forward method is needed since we need to store the ys for giving to the head the right tensors as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0696b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, core_model, output_idxs):\n",
    "        super().__init__()\n",
    "        self.core = core_model\n",
    "        self.idxs = output_idxs\n",
    "        \n",
    "    def forward(self, *args, **kwargs):\n",
    "        x = self.core(*args, **kwargs)\n",
    "        return tuple(x if j == -1 else self.core.last_y[j] for j in self.idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_layers = list(core_model.model.children())\n",
    "last_layer = list_of_layers.pop(-1)\n",
    "\n",
    "core_model.model = torch.nn.Sequential(*list_of_layers)\n",
    "core_wrapper = CoreModelWrapper(core_model, last_layer.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc4d01",
   "metadata": {},
   "source": [
    "Now we are ready for optimizing the body of YOLOv5 using the `nebullvm` function `optimize_torch_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10deb914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Optimize without Quantization\n",
    "# model_optimized = optimize_torch_model(\n",
    "#     model=core_wrapper,\n",
    "#     batch_size=1,\n",
    "#     input_sizes=[(3, 384, 640)],\n",
    "#     save_dir=\".\",\n",
    "#     use_torch_api=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c15b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcf6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = \"zidane.png\"\n",
    "Image.open(requests.get(imgs[0], stream=True).raw).save(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_crop(im, original_model, img_size):\n",
    "    p  =  next(original_model.parameters())\n",
    "    im = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im)\n",
    "    max_y, max_x = im.size\n",
    "    ptr_x = np.random.choice(max_x-img_size[0])\n",
    "    ptr_y = np.random.choice(max_y-img_size[1])\n",
    "    im = np.array(im.crop((ptr_y, ptr_x, ptr_y + img_size[1], ptr_x + img_size[0])))\n",
    "    x = np.expand_dims(im, axis=0)\n",
    "    x = np.ascontiguousarray(np.array(x).transpose((0, 3, 1, 2)))  # stack and BHWC to BCHW\n",
    "    x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 to fp16/32\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51757959",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [((read_and_crop(img_name, core_model, (384, 640)),), None) for _ in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01adfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize with Quantization\n",
    "model_optimized = optimize_torch_model(\n",
    "    model=core_wrapper,\n",
    "    save_dir=\".\",\n",
    "    dataloader=input_data,\n",
    "    use_torch_api=True,\n",
    "    perf_loss_ths=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2866c",
   "metadata": {},
   "source": [
    "Now let's regroup together the optimized body and the head of YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedYolo(torch.nn.Module):\n",
    "    def __init__(self, optimized_core, head_layer):\n",
    "        super().__init__()\n",
    "        self.core = optimized_core\n",
    "        self.head = head_layer\n",
    "    \n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        x = list(self.core(x)) # it's a tuple\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f973f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_core = OptimizedYolo(model_optimized, last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e39d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.model = final_core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe285d08",
   "metadata": {},
   "source": [
    "Finally we can check the speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for _ in range(100):\n",
    "    st = time.time()\n",
    "    results = model(imgs)\n",
    "    times.append((time.time() - st)*1000)\n",
    "yolo_optimized_time = sum(times) / len(times)\n",
    "print(f\"{yolo_optimized_time} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50807de",
   "metadata": {},
   "source": [
    "What an amazing result, right?!? Stay tuned for more cool content from the Nebuly team :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012656ae",
   "metadata": {},
   "source": [
    "## Post the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214ef4b",
   "metadata": {},
   "source": [
    "You can now share the result you gor with the whole community. Just copy and paste the text below on the community main channel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d65b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_username = \"Put here your username\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4433448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomment the following line for installing gputil (if you are running on an NVIDIA GPU)\n",
    "#!pip install gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30260a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cpuinfo\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cpu_info = cpuinfo.get_cpu_info()['brand_raw']\n",
    "gpu_info = \"no\"\n",
    "if torch.cuda.is_available():\n",
    "    import GPUtil\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    gpu_info = list(gpus)[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = f\"\"\"\n",
    "Hello, I'm {your_username}!\n",
    "I've tested nebullvm on the following setup:\n",
    "Hardware: {cpu_info} CPU and {gpu_info} GPU.\n",
    "Model: YOLOv5s\n",
    "Vanilla performance: {round(yolo_vanilla_time, 2)}ms\n",
    "Optimized performance: {round(yolo_optimized_time, 2)}ms\n",
    "Acceleration: {round(yolo_vanilla_time/yolo_optimized_time, 1)}x\n",
    "\"\"\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ecfc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
